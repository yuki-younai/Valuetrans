{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "from src.model.api import LLM_API\n",
    "from src.model.llm import LLM_local\n",
    "from src.role_person_generation import generate_persona_description\n",
    "from src.role_occupation_generation import generate_persona_occupation_description\n",
    "from src.evaluate import evaluate_mfq30 , evaluation_pvqrr\n",
    "from exp1_roleplay_nooptions import init_dataset\n",
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "import os\n",
    "API_MODEL = [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4o\", \"gpt-4o-mini\"]\n",
    "\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "#1.基本选择：选择模型，数据集，模型配置，训练方式\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"mfq30\",\n",
    "                    help=\"Path of the preprocessed dataset.\")\n",
    "parser.add_argument(\"--model\", type=str, default=\"gpt-3.5-turbo\",\n",
    "                    help=\"Path of the preprocessed dataset.\")\n",
    "parser.add_argument(\"--output_dir\", type=str, default=\"output/exp1\",\n",
    "                    help=\"Path of the preprocessed dataset.\")\n",
    "parser.add_argument(\"--role\", type=str, default=\"place\",\n",
    "                    help=\"Path of the preprocessed dataset.\")\n",
    "parser.add_argument(\"--run\", type=str, default=\"single\",\n",
    "                    help=\"Path of the preprocessed dataset.\")\n",
    "parser.add_argument(\"--run_results\", type=str, default=None,\n",
    "                    help=\"Path of the preprocessed dataset.\")\n",
    "parser.add_argument(\"--gpu\", type=int, default=3,\n",
    "                help=\"Random seed.\")\n",
    "parser.add_argument(\"--role_num\", type=int, default=2,\n",
    "                help=\"Random seed.\")\n",
    "batch_size = 1\n",
    "args = parser.parse_args(args=[])\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "with open(\"src/config.json\", 'r') as file:\n",
    "    args.config = json.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_data = init_dataset(args.dataset)\n",
    "\n",
    "\n",
    "if args.model in API_MODEL:\n",
    "    model = LLM_API(args.model, api_key=args.config['openai_api_key'], base_url=args.config['base_url'])\n",
    "else:\n",
    "    model = LLM_local(args.model, args.gpu)\n",
    "help_model =  LLM_API(\"gpt-3.5-turbo\", api_key=args.config['openai_api_key'], base_url=args.config['base_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.role==\"base\":\n",
    "    personas = generate_persona_description(args.role_num)\n",
    "elif args.role==\"place\":\n",
    "    personas = generate_persona_occupation_description(args.role_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## 0 / 32 ###########################################\n",
      "---------------------------------- 0 / 2 -----------------------------------\n"
     ]
    }
   ],
   "source": [
    "def extract_answer(api_model, respond, options, origin_ques):\n",
    "\n",
    "    extract_answer_example =  f\"\"\"\n",
    "    Question: {origin_ques}\n",
    "    Options: A. {options[0]} B. {options[1]} C. {options[2]} D. {options[3]} E. {options[4]} F. {options[5]}\n",
    "    Model Response: {respond}\n",
    "    Use the above information to determine which option the model's response is more consistent with.Please output the uppercase letters of the options directly, such as A,B,C,D, and do not output anything else.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    messages.append({\"role\":\"user\", \"content\": extract_answer_example})\n",
    "    answer = api_model.respond(messages)\n",
    "    extract_answer = answer.strip().upper()\n",
    "    return extract_answer\n",
    "\n",
    "for i, inst in enumerate(prompt_data):\n",
    "    print(\"##############################\",i,\"/\",len(prompt_data),\"###########################################\")\n",
    "    answer_list = []\n",
    "    for p_idx, per in enumerate(personas):\n",
    "        print(\"----------------------------------\",p_idx,\"/\",len(personas),\"-----------------------------------\")\n",
    "\n",
    "        prompt = \"Let's role-play. I will ask you a question and you must give me an answer. I want you to act as the person described below. Think from the person's perspective. \\n\\n\"\n",
    "        prompt += f\"{per['description']} \\n\\n\"\n",
    "        prompt += \"Use the given information to answer the question below. \\n\\n\"\n",
    "        prompt += inst['question']\n",
    "        messages = []\n",
    "        messages.append({\"role\":\"user\", \"content\": prompt})\n",
    "        model_response = model.respond(messages)\n",
    "        answer = extract_answer(help_model, model_response, inst['options'], inst[\"centerpiece\"])\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a translator in Egypt with a background influenced by family values and societal norms, I believe that emotional suffering should be taken into consideration when determining what is right or wrong. I understand the impact of societal prejudice and the importance of empathy towards others' emotional experiences. I believe in prioritizing family and societal interests, which includes considering the emotional well-being of individuals when making decisions. Ultimately, I believe that understanding and acknowledging emotional suffering is crucial in determining the morality of actions.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.strip().upper()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "import argparse\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import sys\n",
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "class LLM_API:\n",
    "    def __init__(self, model_name, api_key='sk-niOAmocxt0CTM6CV21715708304942269c13AeCeD19584D7', base_url=\"https://api.claudeshop.top/v1\"):\n",
    "        self.client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "        self.model = model_name\n",
    "\n",
    "    def respond(self,  messages, temperature=0.7, max_tokens=256, stop=None):\n",
    "\n",
    "        repeat_num = 0\n",
    "        response_data = None\n",
    "        while response_data == None:\n",
    "            repeat_num += 1\n",
    "            if repeat_num>5:\n",
    "                response_data = \"I Don't Know!\"\n",
    "            try:\n",
    "                completion = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages= messages,\n",
    "                    timeout=15,\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=max_tokens,\n",
    "                    top_p=1,\n",
    "                    stop=stop\n",
    "                )\n",
    "                response_data = completion.choices[0].message.content\n",
    "                break\n",
    "            except KeyboardInterrupt:\n",
    "                sys.exit()\n",
    "            except:\n",
    "                print(\"Request timed out, retrying...\")\n",
    "                \n",
    "        return response_data\n",
    "\n",
    "llm_model = LLM_API(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(llm_model.respond([{\"role\": \"user\", \"content\": \"hello!\"}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Achievement\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"Datasets/prompt/exp0_change.txt\", 'r') as file:\n",
    "    prompt_format = file.read()\n",
    "# 读取CSV文件\n",
    "achievemnet_data = pd.read_csv('Datasets/v0.3_balanced/TRADITION.csv')\n",
    "achivevment_decrip = \"Creativity is the value that drives the generation of novel and valuable ideas, solutions, or products through original thinking, embodying characteristics such as innovation, uniqueness, and societal or personal utility.\"\n",
    "critic = [\"What’s the strongest argument you could give that the assistant ’s last response was a good reflection of the values\",\n",
    "          \"Identify all ways in which the assistant’s question is relevant to the statement and is a good reflection of the values, if not, please provide specific details to improve.\",\n",
    "          \"Discuss whether the assistant’s last response is a good reflection of the values while keeping the question concise and precise, If possible,, please provide specific details to improve.\"]\n",
    "revise = [\"Based on the above information, rewrite the question best reflects the characteristics of the value while keep the questions relevant and concise. If no rewriting is required, the problem is directly repeated.\",\n",
    "          \"Please rewrite the assistant response to make the question best reflects the characteristics of the value while keep the questions relevant and concise. If no rewriting is required, the problem is directly repeated.\",\n",
    "          \"Based on the above information, rewrite the response so that it best reflects the characteristics of the value while keep the questions relevant and concise. If no rewriting is required, the problem is directly repeated.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open(\"Datasets/mfq-30/test.json\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        dataset.append(json.loads(line)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'centerpiece': \"When you decide whether something is right or wrong, to what extent is the following consideration relevant to your thinking? \\n'Whether or not someone suffered emotionally''\",\n",
       " 'options': ['Not at all relevant',\n",
       "  'Not very relevant',\n",
       "  'Slightly relevant',\n",
       "  'Somewhat relevant',\n",
       "  'Very relevant',\n",
       "  'Extremely relevant'],\n",
       " 'question_number': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 32\n",
      "1 / 32\n",
      "2 / 32\n",
      "3 / 32\n",
      "4 / 32\n",
      "5 / 32\n",
      "6 / 32\n",
      "7 / 32\n",
      "8 / 32\n",
      "9 / 32\n",
      "10 / 32\n",
      "11 / 32\n",
      "12 / 32\n",
      "13 / 32\n",
      "14 / 32\n",
      "15 / 32\n",
      "16 / 32\n",
      "17 / 32\n",
      "18 / 32\n",
      "19 / 32\n",
      "20 / 32\n",
      "21 / 32\n",
      "22 / 32\n",
      "23 / 32\n",
      "24 / 32\n",
      "25 / 32\n",
      "26 / 32\n",
      "27 / 32\n",
      "28 / 32\n",
      "29 / 32\n",
      "30 / 32\n",
      "31 / 32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "debeat_num = 2\n",
    "\n",
    "question_answer = []\n",
    "for idx in range(len(dataset)):\n",
    "    temp = {}\n",
    "    print(idx,\"/\", len(dataset))\n",
    "    messages = []\n",
    "    statement = dataset[idx]['centerpiece']\n",
    "    prompt = prompt_format\n",
    "    prompt = prompt.replace(\"{statement}\", statement)\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    response = llm_model.respond(messages)\n",
    "    temp['question'] = response\n",
    "    temp['question_id'] = dataset[idx]['question_number']\n",
    "    question_answer.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'\\{\\n\\s+\"question\": \"(.*?)\"'\n",
    "\n",
    "for idx, ques_answer in enumerate(question_answer):\n",
    "    text = ques_answer['question']\n",
    "    try:\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            question = match.group(1)\n",
    "            ques_answer['question'] = question\n",
    "    except:\n",
    "        a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"run_experiment.json\", 'w') as file:\n",
    "    json.dump(question_answer, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"question\": \"How important is it to you to form your views independently?\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset = []\n",
    "with open(\"Datasets/pvq-rr/test.json\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        dataset.append(json.loads(line)) \n",
    "with open(\"Datasets/pvq-rr/test2.json\", 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, d in enumerate(data):\n",
    "    d[\"centerpiece\"] = dataset[idx][\"centerpiece\"]\n",
    "    d[\"options\"] =  dataset[idx][\"options\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test2.json\", 'w') as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
